{"noir_version":"0.35.0+b848cc128d2dc2b461581f21a35509a1af9065a7-x8664","hash":8656169442883101105,"abi":{"parameters":[{"name":"blockheader_serd","type":{"kind":"array","length":24,"type":{"kind":"field"}},"visibility":"public"},{"name":"nsk_m","type":{"kind":"array","length":2,"type":{"kind":"field"}},"visibility":"private"},{"name":"note_content","type":{"kind":"array","length":3,"type":{"kind":"field"}},"visibility":"private"},{"name":"contract_address_as_field","type":{"kind":"field"},"visibility":"public"},{"name":"nonce","type":{"kind":"field"},"visibility":"private"},{"name":"storage_slot","type":{"kind":"field"},"visibility":"private"},{"name":"witness_membership_serd","type":{"kind":"array","length":33,"type":{"kind":"field"}},"visibility":"private"},{"name":"low_nullifier_membership_witness_serd","type":{"kind":"array","length":24,"type":{"kind":"field"}},"visibility":"private"}],"return_type":null,"error_types":{}},"bytecode":"H4sIAAAAAAAA/+1dCZwUxdWvmeU+dBHBC2RBUBCBrrkHATkFFBAFbxHmVBTBwKKYKJ6gcsilgBiNxkgS4/HFeCQacxsTc5jEL+aWJEZz+EVzGE1iNN9r6HZqm9plZvr/NlXG/v3+TFM79bre+7/3r6qe3tmI2HM81iDECdE95xFCd0KDqBzjvVcn3CHfadterFCW8WQpnXRSuUSymIrHirG0U0wky1JmZCybyMTj5UIiU8zE4uVYOlZ4Bzs+x/XdC8PuOBxMeMc7P8Q7P5NwFuFsQkcvTlGx9xEBx+5soJ+a4aJsx9RYnOO9zvMD0uC9uj94O9A2TwmafzQwBjHupBKJUjpWknGZc2LZfCbpJJL5VIZyLZlJFmOUbaVMIpPO5rNpJysT8ZIsJ7PxUnnPcQ7AVtkb2DzBQ24UHD+kz+cqtmQmHoul4+77MkVHJoqFWCYWK+YTTsHJFWKlbEJmy4lYIl4oFvJkMyfLTjlXyJYze8blFmIHTf4IgS/EcwVWcPxjPueA5zPYXQBMBi6/FygBBtnVjhUhAAsY7ObAyeqLtWs3OOuhx56vf+xx3dj7ij0i4Y/Vncn92f0s5Xyecp73zv1+BUKRUCKUlXb/QAvuYcB4FgRPLvQm3Cn2rIbUPGgrN5xwR4u4OCEPNY/P817PDzqAXokgiT2veluFfdiS5wMD254J0U/wJMRC7/UCwZwQ/YAJsRCYEBcIOxPiUMGTEBd6r4sEc0IcCkyIC4EJsUjYmRADBE9CXOS9LhbMCTEAmBAXARNiscCuK9y7Tz2UOPq2aUuYLKSzhUIqlyzk86VSOV1M5TJlmU/lZCwfl7FcLh7PJBJOrlQu5RPxbEomMoUMjThdcBLZ4N0iuqOULxdlMZdM5NNOKlZM5ZNuIErxVD7rpOOpeNIpp8r5nCNjsUwhIQvpmJPNJp1sOZl2ZInj7lMLe6ViXpZi2XghXihlZb5MTpToNJdLOsVYIZmQ5Vy2SITQuMhdh+5M5GWhnIsV8vF4Ml3ey994QhZT6WQ5R+vjUqEUlzKeKybjhVw8QXGI52U2nypl06mYk0ilqS1B4YslCgmKcrEUT3L7G3cSsVQplciVSjS+bDZTkPFCplAqFYq5eC6dzjjpYr5EI47lC7FyPF92SrlSJinzRJ90CnvdXST3ZDKVc1KZcoo8jsVjdDshm8onXMbTiVSKzMXzmbSUhWSMgkjOUgrJZL7gxBOlXIqd3wTlVZySk0rNoZorFjKxUiaXTOayyVgxUSzHnFgyVS45VGvFbCJLzZSDOccpO7l8We7NRy7jZkLKKTr0TzlZzFAZJ7LFRKZMoU0UHSoHJ5/NlIppmc5l88l4LFdOxSlyybiTzkoOf7t4ttxzd5nq76vOV84XKucXKOcXKueLlPOLlPPF3vkSwsWED4iWB3pPuhQXn7huT7pU8e1w5XyJaH1PuozQTFhOuETsvSdFx+BSXAwSuhhcqvjaXzlf1kYMVhAuI3yQ8CGvfV/3J5xwh2zC2XKaPDuXE64grCRcSbiKcDXhGsK1hOsIqwirCdcTbiDcSFhDWEtYR1hPuImwgbCRsImwmbCFcDPhFsJWwjbCdsKthB2E27yYqXv7y71Xte0KTdtKTduVmrarNG1Xa9qu0bRdq2m7TtO2StO2WtN2vabtBk3bjZq2NZq2tZq2dZq29Zq2mzRtGzRtGzVtmzRtmzVtWzRtN2vabtG0bdW0bdO0bde03app26Fpu03svRHw63u89+qEO1rUbFgdvBxgy/8w6QrguIpRng+TglyE9Lm4EmcreyXOlrwKyEXJCi5K8mqYrYK8BmYrI68FclG2ggtHXoeyVXLkKpStgiNXA7k4zwYuMo68HmWL5p4bQLZKZOtGIBfnW8BFgXxeA7KVIVtrQbbIZbkOyMVC87kouT6vx9gquLZuwthyHwWRG4BcXGA+F65puRFiq7Tb1iaIrcJuW5uBXFxoPBe7n0SSWyC2dg9T3oywVdpj6xYgF4tM56Kwx+etCFveA2bbELb2uCy3A7m4yHAuip7PtwJs5T1bOwC20p6t24BcLG4nLpxwhwTeH5DA/a1U92dhuVhiCRfAfZAEruPlQiAXF1vCBXC9J4HrFbkIyMUHLOECOK9JoC7LJUAuljJxgX7uBFi/Eph/Eh0/9OeDA0Xl8zPVbti8uYbZ77DjW8Hk97WWaNcKoM8fBo4LmDfSFi4GArm4namGTa0LdP3eIewY50fqH2cs2KB7vsWtaf85ltuV8zuU84+Ils+33Em4i/BRwt0Be8h6GSQqz3cgY7ra8DnrCi/GaLvXW6KTdwJ9/hhwXMC8kbZwMQjIxT1MNWxSXeg01s1BX0vvEdVp7E7CxwmfIHxS8GnsEaLyvJwA8rPGcI1d6cUYbXetJXW9E+jzvcBxAfNG2sLFEUAuPsVUwybVhU5j3Rz0tfRTojqNvY9wP+EBwoOCT2MHi8rzxwLIz02Ga+yVXozRdjdYUtf3AX3+H+C4gHkjbeFiMJCLTzPVsEl1odNYNwd9Lf20qE5jHyJ8hvAw4RHBp7FDROX3OQSQn82Ga+xVXozRdrdYUtcPAX1+FDguYN5IW7gYAuTiMaYaNqkudBrr5qCvpY+J6jT2s4TPER4nPCH4NPZIUfn9OAHkZ6vhGnu1F2O03W2W1PVngT5/HjguYN5IW7g4EsjFk0w1bFJd6DTWzUFfS58U1WnsFwhfJHyJ8GXBp7FHicrvGwsgPzsM19hrvBij7d5mSV1/AejzV4DjAuaNtIWLo4BcfJWphk2qC53Gujnoa+lXRXUa+zXCU4SvE54WfBo7VFS+v0EA+bnDcI291osx/BkVS+r6a0CfvwEcFzBvpC1cDAVy8U2mGjapLnQa6+agr6XfFNVp7DOEbxG+TfiO4NPYYaLyfTgCyM9HDdfY67wYo+3ebUldPwP0+bvAcQHzRtrCxTAgF88y1bBJdaHTWDcHfS19VlSnsd8jfJ/wA8Jzgk9jjxaV7xcTQH52Gq6xq7wYo+1+3JK6/h7Q5/8FjguYN9IWLo4GcvFDpho2qS50GuvmoK+lPxTVaezzhB8Rfkz4ieDT2OGi8n2NAsjPvYZr7Govxmi7n7Kkrp8H+vxT4LiAeSNt4WI4kIufMdWwSXWh01g3B30t/ZmoTmN/TvgF4QXCLsGnsceIyvffCiA/Dxiusdd7MUbbfdCSuv450OdfAscFzBtpCxfHALn4FVMNm1QXOo39paho6a9EdRr7a8KLhN8QXhJ8GjtCVL5PXAD5echwjb3BizHa7mcsqetfA31+GTguYN5IW7gYAeTit0w1bFJd6DTWzUFfS38rqtPY3xF+T/gD4RXBp7EjReXvMwggP48arrE3ejFG233Mkrr+HdDn/wOOC5g30hYuRgK5+CNTDZtUFzqNdXPQ19I/iuo09lXCa4Q/Ef4s+DR2lKj8vRsB5OdxwzV2jRdjtN0nLKnrV4E+/wU4LmDeSFu4GAXk4q9MNWxSXeg01s1BX0v/KqrT2NcJfyO8QXhT8GmsmzxrBV5rvmC4xq71Yoy2+0VL6vp1oM9/B44LmDfSFi4cIBf/YKphk+pCp7FuDvpa+g9Rncb+k/AW4V+EtwWfxkpR+XuMAsjPVwzX2HVejNF2v2pJXf8T6PM7wHEB80bawoUEcvFvpho2qS50GvuOqGjpv0V1Gus2RghRQkOET2NjovL3bQWQn68brrHr/RiD7T5tSV27jqN87hDBjQuYN9IWLmLA/OsY4alhk+pCp7FuDvpa2jFSncZ2osbOhC6ErowaGxeVvxcugFw/Y7jG3uTFGG33W5bUdSdgLXYDaiwwb6QtXMSB+dc9wlPDJtWFTmO7KbravUqN7UGNPQn7EfZn1NgE2dgg8FrzXcM1doMXY7TdZy2p6x7AWmwEaiwwb6QtXCSA+dcrwlPDJtWFTmMbFV3tVaXGHkCNvQkHEvowamySbGwUeK35geEau9GLMdruc5bU9QHAWuwL1Fhg3khbuEgC8++gCE8Nm1QXOo3tq+jqQVVq7MHUeAjhUMJhjBqbIhubBF5rnjdcYzd5MUbb/ZEldX0wsBb7ATUWmDfSFi5SwPzrH+GpYZPqQqex/RRd7V+lxh5OjQMITYSBjBqbJhubBV5rfmq4xm72Yoy2+zNL6vpwYC0OAmosMG+kLVykgfl3RISnhk2qC53GDlJ09YgqNXYwNQ4hHEk4ilFjM2Rji8BrzQuGa+wWL8Zou7ssqevBwFocCtRYYN5IW7jIAPNvWISnhk2qC53GDlV0dViVGns0NQ4nHEMYwaixWbJxs8Brza8N19ibvRij7b5oSV0fDazFkUCNBeaNtIWLLDD/RkV4atikutBp7EhFV0dVqbGuIUmIEeKMGjuabNwi8FrzsuEae4sXY7Td31pS1w6wFhNAjQXmjbSFi9HA/EtGeGrYpLrQaWxC0dVklRqbosY0IUPIMmrssWRjq8BrzR8M19itXozRdl+x5XMWYC2OBmosMG+kLVwcC8y/YyM8NWxSXeg0drSiq8dWqbFjqHEsYRzhOEaNHUM2tgm81rxquMZu82KMtvuaJXU9BliL44EaC8wbaQ0XwPybEOGpYZPqQqex4xVdnVClxk6kxkmEyYQpjBo7lmxsF3it+YvhGrvdizHa7l8tqeuJwFo8HqixwLyRtnAxFph/UyM8NWxSXeg09nhFV6dWqbHTqHE64QTCiYwaO45s3CrwWvOG4Rp7qxdjtN03LanracBanAHUWGDeSFu4GAfMv5kRnho2qS50GjtD0dWZVWrsLGo8iTCbcDKjxh5HNnYIvNb803CN3eHFGG33LUvqehawFk8Baiwwb6QtXBwHzL85EZ4aNqkudBp7iqKrc6rU2LnUeCrhNMLpjBrr2rlN4LXmHcM19jYvxmi7/7akrucCa/EMoMYC80bawsV4YP6dGeGpYZPqQqexZyi6emaVGnsWNZ5NOIcwT9FY/4iCee4C5PmsCE9uo/XwXNg446zjnF//OBPBBl1+nqvk5CFKTh6snM+PtMzPBfT/HCFPKGjyswGcn/2BthYAdagY4dWOosJNTjnPK+eFADcl+n+ZcB7hfA036PxciKujpC4GCxVfVyg5WVLjIVrG4AJqvJCwiHBRO8RgMS4P0roYLFZ87a/E4II2YrCEGi8mfICw1ItBR7GnNqNi7wO9fp8seOYBgRmn9E/UWCzzgtAc8QLS4L26P3gh0Oa+qSkwKLTwqUGsM0ljXpLKZUDha2aa5NELG6TPyzW28k6hmJT5VDEtS7lkplDIxqWM5VK5VD6WKZfySZlJZshmIRfL0OViuYIsOblUyS3EDqJSdOqBLsTl4EnKPy6JMA74kgje7qXAZODy+1IlwiC7LHcpmr2xogrWt4vkaAU48X3hd+0OFHtm0/Yq4omCp4gvizAO+DKGIv6g4UXs+v1BhiJuz2SbJHiS7UMRxgF/iCHZLjc82Vy/L7c82ZojPMl2RYRxwFcwJNtKw5PN9XtlOy1PnHDH7lni8gh+2XMl8w0fd/bwN/STlPPmNjb6V1Hj1YRrCNdGWv9ALqzvLvdXMsT0OlxMZfDGBjqvJuBsOQd6dlbRIFcTrifcQLiRsIawlrCOsJ5wE2EDYSNhE2EzYQvhZsIthK2EbYTt3pJcXa6u8jhT21Zr2q7XtN2gabtR07ZG07ZW07ZO07Ze03aTpm2Dpm2jpm2Tpm2zpm2Lpu1mTdstmratmrZtmrbtkb0nUfSHdBMErhZXAeagUnnPsTqCG1e0oX0+MA3pc/F6XPyyN+BsyRuBXDRYwUVJroHFryDXwmxl5DogFx2s4MKR61HxKznyJpStgiM3ALnoaAMXGUduRMWP5p5NIFslsrUZyEUnC7gokM9bQPHLkK2bQbbIZXkLkIvO5nNRcn3eiolfwbW1DWMr49raDuSiSztx4YQ7JHC9J4HrFanOt2G56GoJF8B5TQJ1WXYGctGNiQv08wDA+pXA/JNc8Qt+vGjC/vbdXzgE3rdybUTAuXIVGbwugr9ftyOC5Rrt9xRRueeF9PvABrP9dvNxB4PffdpJG0P/4gSwHoFcyz6G541bL7cy5M3Bhvu9iqleDrGkXj4MrBcg1xIZP5fb4Gdsrk74n6V9OFLdL2TcTo13ED5CuDPC90tvx4vKZzNIrvsx12LY8bk+387gd39L9li3A9eldwHrGpg30hYujgfm30cjPDVsUl3oNPYuRVc/WqXG3k2NHyPcQ9jJqLFTReWzbgHkuslwjXV9vpvB74GW1PXdwFr8OFBjgXkjbeFiKjD/PhHhqWGT6kKnsR9XdPUTVWrsJ6nxXsKnCPcxauw0UXl2SAC5Hmy4xro+f5LB7yGW1PUngbV4P1BjgXkjbeFiGjD/Hojw1LBJdaHT2PsVXX2gSo19kBr/h/BpwkOMGjtdVJ7FFECuhxqusa7PDzL4PcySun4QWIufAWosMG+kLVxMB+bfwxGeGjapLnQa+xlFVx+uUmMfocZHCY8RPsuosSeIyrPtAsj1MYZrrOvzIwx+j7Ckrh8B1uLngBoLzBtpCxcnAPPv8QhPDZtUFzqN/Zyiq49XqbFPUOPnCU8SvsCosSeKyu8KCSDXjuEa6/r8BIPf0pK6fgJYi18Eaiwwb6QtXJwIzL8vRXhq2KS60GnsFxVd/VKVGvtlavwK4auErzFq7AxR+d1LAeQ6YbjGuj5/mcHvpCV1/WVgLT4F1Fhg3khbuJgBzL+vR3hq2KS60GnsU4qufr1KjX2aGr9B+CbhGUaNnSkqv8sugFxnDNdY1+enGfzOWlLXTwNr8VtAjQXmjbSFi5nA/Pt2hKeGTaoLncZ+S9HVb1epsd+hxu8SniV8j1FjZ4nKd4MIINdjDNdY1+fvMPg91pK6/g6wFr8P1Fhg3khbuJgFzL8fRHhq2KS60Gns9xVd/UGVGvscNf4v4YeE5xk19iRR+a4lAeR6vOEa6/r8HIPfEyyp6+eAtfgjoMYC80bawsVJwPz7cYSnhk2qC53G/kjR1R9XqbE/ocafEn5G+Dmjxs4Wle+uE0CuJxuusa7PP2Hwe4oldf0TYC3+AqixwLyRtnAxG5h/L0R4atikutBp7C8UXX2hSo3dRY2/JPyK8GtGjT1ZVL4LVAC5nma4xro+72Lwe7oldb0LWIsvAjUWmDfSFi5OBubfbyI8NWxSXeg09kVFV39Tpca+RI0vE35L+B2jxp4iKt+tLIBczzBcY12fX2Lwe6Yldf0SsBZ/D9RYYN5IW7g4BZh/f4jw1LBJdaHT2N8ruvqHKjX2FWr8P8IfCa8yauwcUfmuegHkerbhGuv6/AqD3ydbUtevAGvxNaDGAvNG2sLFHGD+/SnCU8Mm1YVOY19TdPVPVWrsn6nxL4S/El5n1Ni5ovK3PwSQ67mGa6zr858Z/D7Vkrr+M7AW/wbUWGDeSFu4mAvMvzciPDVsUl3oNPZviq6+UaXGvkmNfyf8g/BPRo09VVT+lpIAcn2G4Rrr+vwmg99nWlLXbwJr8S2gxgLzRtrCxanA/PtXhKeGTaoLnca+pejqv6rU2Lfd9xH+7f4wyqexp4nK36YTQK7PMVxjXZ/fZvB7niV1/TawFiNR3LiAeSNt4eI0YP5Fozw1bFJd6DTWzUFfS6PR6jS2wdVVQkdCJ0aNPV1U/tanAHK9wHCNdX12Y4y2m7OkrhuAtdgZqLHAvJG2cHE6MP+6RHlq2KS60GlsZ0VXu1SpsV3pfd0I3Qk9GDX2DNHybyejYlo0XGNdn7syaGzJkrruCqzFnkCNBeaNtIWLM4D5t1+Up4ZNqgudxvZUdHW/KjV2f3pfI6EX4QBFY/0jCua5G5Dn/aM8ud0A9nki0OclwL13b2D8Ono5FRF7H+j5GjludbwHRhkHfGAUb7cPUOi4/O4TrQQYZHd3snn3NtmTbUmER2TQ45woeIqir5K38JViH+CqqWNgjLYEW03ig7z/HOwGnSPYfRlUqC94GubyO8rod9gxHsIcQyfcId3EPIRhq3goeCpv8Hx37V7l2UXH4mCmWBzGFIvDGGPhCiFHLM43/NYJVz0s/M/6XdjH+Nhy/4J2+jO2TrhDAvNSArmWyPi5C6mo0K+uRY3x3Fc+qTY55ixUTNRFZb+2VsROuEMewjQJqIOuccxyX9dxx9yPQRQWG3LvspbFW1if+0fNFJjFDTx52V9ZnNTLz75ijuTncMWWjMepNoppWS6W48l0NpaXqXgqVU6U06lMolhOJnLFdEkmcvFYtpR2yjJTKqWT8UI6Vc4WC6myKtqyGI8nitl8QSZjqVzeyRTjOaecSMdjTq4YTxeL8UwqlYvHi6lMOZPNxGK5cjzjJNPprJOKxbMxLn4O9/hpz9018paLOokN8P7TZIuAc41vAINYD2SauAYy7l7cWDQxxGIQUywGMcbCLTqOlf3Fhu/kuOrhA4bv5Lhyf6klOzlgXkog13Lp+zu54CEHMO3kjrBxJ3cE807uCAZRuOS/cCc3OGqmwFzCtFMYbNlObghwJ7cUuJPj4meIspNrbVIw+RYc5zi5JpgjbZxgjmSeYI5kmGBWtNMEg/yc16DPilpMMGHHdVk77QDCjvMo4AQNzD95GdMEcFQVE3TYmA6N4ibCFrdHDZqgVzDxM/Q9dKt1mPefo6OaB5mccIds7YEe5NNoYW0BH4qSHMT7MUSLKlcMw9oabjgfbsEMZ1gYHcO0SDwmyncr+mimWIxgisUI5tvyHLG43PDb8lz1cIXht+W5cn+lJbflgXkpgVzLle/flg8eu+csVEzUxe5Izrsmw5kmgZGMd03cMY9kEIVrLLktPxy4EBwVNVNgrmHaVY6K8t+WR/LjAG/LrwTu+rn4cf4Du/6JOFstdv3S+0/MFgHnGp9kEOs408QVZ9y9uLGIMcQiwRSLRJT3V2U4VvbXGb6T46qHVYbv5Lhyf7UlOzlgXkog13L1+zu54CEl004uaeNOLsm8k0syiMKa/8KdXCpqpsCsYdoppCzbyaWBO7nVwJ0cFz/paPs/YIW8Bcc5Tq4JJmPjBJNhnmAyDBPMOksesEIK2BVMK9iw41pvyQNWWeAEDcw/uZ5pAshG+R+wGh3FTYQrG8ycoNcx8TNaww/HczWosXOOs2/UDg2ZBPQZ+d2JxwLj157fnYgctzreMVHGAY+J4u2OBS4UuPweG60EGGS3Xb87EVi8rGKIfApWLYpxbe1OwibdWODqSp0l/UG/Fx5DPs77z/iowH+fokvAOAZlGgeemrn8jjL6HXaME5hj6IQ7pJuYExi26ROZbllMjPJ9MDqeKRaTmGIxKcr7uC9HLDYa/iExVz1sMvxDYq7c32zJh8TAvJRAriUyfu+VD4mPY9o6To4y3sOfwDQJTGa8h++OeTKDKGy15EPiCcCF4JSomQKzleke55Qo/4fESH6Oj+LuQW8G3oPm4uf4aPs/7ou8DaNOYlO9/0yzRcC5xjeVQaynM01c0xl3L24spjHE4gSmWJzAGAu36DhW9tsN38lx1cOthu/kuHJ/hyU7OWBeSiDXcsf7O7ngIacy7eROtHEndyLzTu5EBlG4479wJzcjaqbA3MG0U5hh2U5uJnAntwO4k+PiZ2a0/R/3Rd6C4xwn1wQzy8YJZhbzBDOLYYK505LHfZECtolpBRt2XHdZ8rjvScAJGph/8i6mCeCkKP/jvrOjuIlwc4OZE/SdTPzMfg/daj3Z+88pUYH/PsXWHuhBPqEW1hbwoSiW7+/zY4gWVa4YhrU1x3A+3IKZw7Awmsu0SJwb5bsVfQpTLE5lisWpzLflOWLxMcNvy3PVwz2G35bnyv2dltyWB+alBHItd75/Wz547J6zUDFRF7uncd41mcM0CZzGeNfEHfNpDKJwryW35ecAF4KnR80UmHuZdpWnR/lvyyP5OQN4W34ncNfPxc8Z/4FdP9evL53p/ecsWwSca3xnMoj12UwT19mMuxc3FmcxxOIcplicE+X9VRmOlf19hu/kuOrhfsN3cly5/4AlOzlgXkog1/KB93dywUOeybSTm2fjTm4e805uHoMoPPRfuJM7N2qmwDzEtFM417Kd3HzgTu4B4E6Oi5/50fZ/wAp5C45znFwTzAIbJ5gFzBPMAoYJ5mFLHrBCCtg9TCvYsON6xJIHrHLACRqYf/IRpgkgF+V/wCofxU2EOxvMnKAfZuIn38bdHcRzL672RAN2nXCHROpZgfnOaei/+UcGCwwxXIm73S0LQD4iGn04mHAI4VDCYYR+hMMJAwhNhIGEQYQjCIMJQwhHEo4iDCUMIxxNGE44hjCCMJIwyvXdrU1CzB07IUFIElKENCFDyBJGE44ljCGMJYwjHOeNcQJhImESYTJhCuF4wlTCNMJ0wgmEEwkzCDMJswgnEWYTTiacQphDmEs4lXAa4XTCGZ7v/uHGx82FBi9O7sK6E6EzoQuhK6EboTuhB6EnYT/C/oRGQi/CAYTehAMJfQh9CQcR+ivX2aac91TOe3uvly5dsvi8psXLFy1aWF5YWtp0Yeky4V3KPw7zXgu5RYuampc05ZYtKy1tnn9RbsX8/MLm+csWfrDk/vg1pYs/gtlLl1yy0LW/pLnUtHBxYdHyZQuXLG4q5xYuKhXdN2xVFrwnBTu9O6jFSxaPCPYe3TRpyfJFRdd008XUo9S0aMmlSp933++a/EikZnfuqr3LvbV3ua/2Lg/W3uXTtXd5vPYun6+9y1dq7/K12rt8o/Yuz9Te5bnau/yw9i4/rr3LT2vv8mLtXV6qvcsrtXf5Y+1dXlW6nOW9VisxJCnz333PyEtyi5aXmsY0BVsK55cKFyqi9lq7X/EftYflrdq7dIjW3KVT7V261t6le+1dDqy9S9/au/SrvcvhtXcZVHuXwbV3GVF7l1G1d4nV3iVRe5extXc5rvYuU2rvMrX2LtOVLvO91/rUZnFpRfP8PQIzrk3JcaVjf+9SIytXf3eBO2Hp0txltAIrllY0LVne3LSk3JRfsnxxcZna8VilYz/vNdfcXLro4ubd3haLTZcubD6/iZZ2S8s0ULXvcfVedFYdF+1Vr6e9Qnjaq15Pe4XwtHe9nvYO4Wnvej3tHcLTPvV62ieEp33q9bRPCE9v8+b5mNJ34N59ly3PNy/NFZpbN5CqddR+x7H1dpxRh7sf9vrWTKzfsR5i/b41E+t3rIfYnV7fpNK3JmJ9A9laR+13HF9vx5PqcPf+eom9PwSx99dL7P0hiH00LLGP1kvso/US+2gIYp8M6+6T9br7ZL3uPhnC3afqzeOnQuTxU/Xm8VMh8vjZsMQ+Wy+xz9ZL7LMhiH2+XmKfD0Hs8/US+3wIYneFJXZXvcTuqpfYXSGIfTmsuy/X6+7L9br7cgh3Xw+7YHy93gXj6/UuGF8PsWB8o96yfSNE2b5Rb9m+EaJs/c8e685j30DNeex3HF9vx3ryuLPXt2Zi/Y71EOv3rZlYv2M9xDaGJbaxXmIb6yW2MQSxB4V196B63T2oXncPCuHugHrzeECIPB5Qbx4PCJHHw8ISO6xeYofVS+ywEMQ69RLrhCDWqZdYJwSx2bDEZuslNlsvsdkQxI4P6+74et0dX6+74+t0991f7T3Ze3WfW/E/kHANdxC455O6KoOD2s4kUl1F5XkljnF35LHtuM8LTeqyx5Y/fv9a7vM+/nOv/nvcl27Kzyd77Q1K25SAvd7K+6IKzyw+Scdxx9BJtDzc63XmuJ4Tk5HAtToo5/41uyljQudHRLmOf33/Wn683Y913Oe8fJ46BsbX5HfuqfxQKANuzUGV0AalfTzGOadRGY+aZJ1F7WNsVPqpthrqsOX620XA/ZWNyni6aK6FTR7pdPXs4207jv8QIjRGco/d7jxjlj1FhW8/Lm4xDVKu57f7f+y7Q4Cvjsp7jlZsDPHO9xeVAu2otAWLUh2LTpR9G929/l0D7+0qKg9tgkVv9wO6+7USh55Ku/+eUd7rAWLvQ7UlhF7AIqLlA6gdlD7+dd0Y9AiMoUF5Xw+lv/petf57KtfV9VPPuwb6qFrVQ3Odzm34EswhNc86idbj679njPeqi29XxReOPNhfGU8HZXxqfvjvGd/GOFVbQrSeB8Fc8fv411VrwX9vg/JzdSGovrch0O5fV9dPPe8R6KPOM11ruI7/826KnYbA+3Qx8vNC1cTWckflyn+Pv2rXcdJT01fVQ7+vzQt3psV1rKtgW/S1WLh3VHjxOQsu3FUeJ7eymJ8SWMz3VtoiCs8sPnkL9+C6jm/t0/bC3b9mN8G1cdizcO8SuL5/rdYW7p0C42vyO+sWsiYEr4Hl+vrgNbQSvA7VBC+4Zax2F6Bu+3ffC8E4uHvn0ylw7Z6ipdPVjrNR6dehlbEDdxXl9tpVcMw03Xn43G27B8u4Y466a1dn/iHK9YK7luBKVV0RDFdsDPXO1R2Kbqbxfxbcjfh5p1tJRbx+fvsoxf50zdj9uAV3ReqKulPAP/W9/nvi3qsJq+XgSlVdLafbGKduJRicPdpaLasr0+CKnTsGjVXEwH/PuH3EoDHgX0MVMWhU/PRjsH9gDGredRAt81ddtQdtRQLjn+K9BnNa9VVnW9X//ZQ2v566t2K3a8BXvw5UzWytVlSN8N8z03ttbXfQlu6cpvzs/d1Bi+M9uTtQr9NRea+65lBX08j5taNy7VOUsaiaxrIY9nYuah761+NZp7S9+O6mvDKtwXZfv1vg+v61Wtu5dAmMr8nv3NrO5T8dPM6dSzB4+9q5tBm8enYE3DuX4G6jp2jpdLXjbFT68e9ceD9b4NsB7Pkch+dev1NWd8fqVnpo4Hru4a/o/Pf3CLS7x0jFhr/TcFc9/szg5466uuis9Jmr9PFt+jmi3rdXc0T9LCKm2Jqh8cE/V1dJfvt+Spvqp+4zD/8J1tZ2GfsHrjfe+78T6tCvsHX3f/33jG5jnLoVdlDpdTuRRuXcv+5+ynl7xKBXFTHw3zNhHzHoFfCvoYoY9FLO/es2Kueq3/771PxtVK4RtBUJjH+a9xrMadVXnW1Vq9Wdh19PnVux2yHgq/pZpP+e1mpF1Qr/PbO919Z2GW3pz750orW7FOrn60x3lGKM84mj3ivvpvjlH9FAzPwxBM+jomUeB3+ua+upuU5vTVtX5fVAxQZ6Xu3DY7tFjP3x91F8iio/R13TtRHMVzWm6s5KzeEIfiwtvlq7Qey9ZlM593/2//6KJg1MawIA","debug_symbols":"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","file_map":{"24":{"source":"use crate::ops::arith::{Add, Sub, Neg};\nuse crate::cmp::Eq;\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    x: Field,\n    y: Field,\n    is_infinite: bool\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    lo: Field,\n    hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a,b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset+31 - i] as Field) * v;\n            hi = hi + (bytes[offset+15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the \n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N]\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    let point_array = multi_scalar_mul_array_return(points, scalars);\n    EmbeddedCurvePoint { x: point_array[0], y: point_array[1], is_infinite: point_array[2] as bool }\n}\n\n#[foreign(multi_scalar_mul)]\nfn multi_scalar_mul_array_return<let N: u32>(points: [EmbeddedCurvePoint; N], scalars: [EmbeddedCurveScalar; N]) -> [Field; 3] {}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_slice(points: [EmbeddedCurvePoint], scalars: [EmbeddedCurveScalar]) -> [Field; 3] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    let g1 = EmbeddedCurvePoint { x: 1, y: 17631683881184975370165255887551781615748388533673675138860, is_infinite: false };\n    multi_scalar_mul([g1], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// This is a hack because returning an `EmbeddedCurvePoint` from a foreign function in brillig returns a [BrilligVariable::SingleAddr; 2] rather than BrilligVariable::BrilligArray\n// as is defined in the brillig bytecode format. This is a workaround which allows us to fix this without modifying the serialization format.\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    let x_coordinates_match = point1.x == point2.x;\n    let y_coordinates_match = point1.y == point2.y;\n    let double_predicate = (x_coordinates_match & y_coordinates_match);\n    let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n    let point1_1 = EmbeddedCurvePoint { x: point1.x + (x_coordinates_match as Field), y: point1.y, is_infinite: x_coordinates_match };\n    // point1_1 is guaranteed to have a different abscissa than point2\n    let mut result = embedded_curve_add_unsafe(point1_1, point2);\n    result.is_infinite = x_coordinates_match;\n\n    // dbl if x_match, y_match\n    let double = embedded_curve_add_unsafe(point1, point1);\n    result = if double_predicate { double } else { result };\n\n    // infinity if x_match, !y_match\n    if point1.is_infinite {\n        result= point2;\n    }\n    if point2.is_infinite {\n        result = point1;\n    }\n    let mut result_is_infinity = infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n    result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n    result\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(_point1: EmbeddedCurvePoint, _point2: EmbeddedCurvePoint) -> [Field; 3] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    embedded_curve_add_unsafe(point1, point2)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(point1: EmbeddedCurvePoint, point2: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    let point_array = embedded_curve_add_array_return(point1, point2);\n    let x = point_array[0];\n    let y = point_array[1];\n\n    EmbeddedCurvePoint { x, y, is_infinite: false }\n}\n","path":"std/embedded_curve_ops.nr"},"25":{"source":"use crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n\n    let mut low: Field = 0;\n    let mut high: Field = 0;\n\n    let mut offset = 1;\n    for i in 0..16 {\n        low += (x_bytes[i] as Field) * offset;\n        high += (x_bytes[i + 16] as Field) * offset;\n        offset *= 256;\n    }\n\n    (low, high)\n}\n\nunconstrained pub(crate) fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nfn compute_lt(x: Field, y: Field, num_bytes: u32) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..num_bytes {\n        if (!done) {\n            let x_byte = x_bytes[num_bytes - 1 - i];\n            let y_byte = y_bytes[num_bytes - 1 - i];\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nfn compute_lte(x: Field, y: Field, num_bytes: u32) -> bool {\n    if x == y {\n        true\n    } else {\n        compute_lt(x, y, num_bytes)\n    }\n}\n\nunconstrained fn lt_32_hint(x: Field, y: Field) -> bool {\n    compute_lt(x, y, 32)\n}\n\nunconstrained fn lte_16_hint(x: Field, y: Field) -> bool {\n    compute_lte(x, y, 16)\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    unsafe {\n        let borrow = lte_16_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size(128);\n        rhi.assert_max_bit_size(128);\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size(128);\n            xhi.assert_max_bit_size(128);\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(compute_lt(b, a, 32));\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        compute_lt(b, a, 32)\n    } else if a == b {\n        false\n    } else {\n        // Take a hint of the comparison and verify it\n        unsafe {\n            if lt_32_hint(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{decompose, compute_lt, assert_gt, gt, TWO_POW_128, compute_lte, PLO, PHI};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    fn check_compute_lt() {\n        assert(compute_lt(0, 1, 16));\n        assert(compute_lt(0, 0x100, 16));\n        assert(compute_lt(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lt(0, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_compute_lte() {\n        assert(compute_lte(0, 1, 16));\n        assert(compute_lte(0, 0x100, 16));\n        assert(compute_lte(0x100, TWO_POW_128 - 1, 16));\n        assert(!compute_lte(0, TWO_POW_128, 16));\n\n        assert(compute_lte(0, 0, 16));\n        assert(compute_lte(0x100, 0x100, 16));\n        assert(compute_lte(TWO_POW_128 - 1, TWO_POW_128 - 1, 16));\n        assert(compute_lte(TWO_POW_128, TWO_POW_128, 16));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n","path":"std/field/bn254.nr"},"26":{"source":"pub mod bn254;\nuse bn254::lt as bn254_lt;\nuse crate::runtime::is_unconstrained;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size(self, bit_size: u32) {\n        // docs:end:assert_max_bit_size\n        crate::assert_constant(bit_size);\n        assert(bit_size < modulus_num_bits() as u32);\n        self.__assert_max_bit_size(bit_size);\n    }\n\n    #[builtin(apply_range_constraint)]\n    fn __assert_max_bit_size(self, bit_size: u32) {}\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_le_bits)]\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_le_bits\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    /// \n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n    /// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n    /// wrap around due to overflow when verifying the decomposition.\n    #[builtin(to_be_bits)]\n     // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {}\n    // docs:end:to_be_bits\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self', \n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let  p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    /// \n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self', \n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let  p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    // docs:start:to_le_radix\n    pub fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_le_radix(radix)\n    }\n    // docs:end:to_le_radix\n\n    // docs:start:to_be_radix\n    pub fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        crate::assert_constant(radix);\n        self.__to_be_radix(radix)\n    }\n    // docs:end:to_be_radix\n\n    // `_radix` must be less than 256\n    #[builtin(to_le_radix)]\n    fn __to_le_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    #[builtin(to_be_radix)]\n    fn __to_be_radix<let N: u32>(self, radix: u32) -> [u8; N] {}\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32-i] as Field) * (r * self) + (1 - b[32-i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N-1-i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    let x_bytes: [u8; 32] = x.to_le_bytes();\n    let y_bytes: [u8; 32] = y.to_le_bytes();\n    let mut x_is_lt = false;\n    let mut done = false;\n    for i in 0..32 {\n        if (!done) {\n            let x_byte = x_bytes[32 - 1 - i] as u8;\n            let y_byte = y_bytes[32 - 1 - i] as u8;\n            let bytes_match = x_byte == y_byte;\n            if !bytes_match {\n                x_is_lt = x_byte < y_byte;\n                done = true;\n            }\n        }\n    }\n    x_is_lt\n}\n\nmod tests {\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_bytes();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bits), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_bytes();\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bits), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bits), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        let field = 2;\n        let bits: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bits, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bits), field);\n    }\n    // docs:end:to_le_radix_example\n}\n","path":"std/field/mod.nr"},"29":{"source":"pub mod poseidon;\npub mod mimc;\npub mod poseidon2;\npub mod keccak;\npub mod sha256;\npub mod sha512;\n\nuse crate::default::Default;\nuse crate::uint128::U128;\nuse crate::collections::vec::Vec;\nuse crate::embedded_curve_ops::{EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_slice};\nuse crate::meta::derive_via;\n\n// Kept for backwards compatibility\npub use sha256::{digest, sha256, sha256_compression, sha256_var};\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    pedersen_hash_with_separator_noir(input, separator)\n}\n\npub fn pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let value = __pedersen_commitment_with_separator(input, separator);\n    if (value[0] == 0) & (value[1] == 0) {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    } else {\n        EmbeddedCurvePoint { x: value[0], y: value[1], is_infinite: false }\n    }\n}\n\n#[no_predicates]\nfn pedersen_commitment_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n#[no_predicates]\nfn pedersen_hash_with_separator_noir<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: Vec<EmbeddedCurveScalar> = Vec::from_slice([EmbeddedCurveScalar { lo: 0, hi: 0 }; N].as_slice()); //Vec::new();\n\n    for i in 0..N {\n        scalars.set(i, from_field_unsafe(input[i]));\n    }\n    scalars.push(EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field });\n    let domain_generators :[EmbeddedCurvePoint; N]= derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    let mut vec_generators = Vec::new();\n    for i in 0..N {\n        vec_generators.push(domain_generators[i]);\n    }\n    let length_generator : [EmbeddedCurvePoint; 1] = derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    vec_generators.push(length_generator[0]);\n    multi_scalar_mul_slice(vec_generators.slice, scalars.slice)[0]\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator_noir(input, 0)\n}\n\n#[foreign(pedersen_hash)]\nfn __pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {}\n\n#[foreign(pedersen_commitment)]\nfn __pedersen_commitment_with_separator<let N: u32>(input: [Field; N], separator: u32) -> [Field; 2] {}\n\n#[field(bn254)]\npub fn derive_generators<let N: u32, let M: u32>(domain_separator_bytes: [u8; M], starting_index: u32) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(domain_separator_bytes: [u8; M], starting_index: u32) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    let (xlo, xhi) = unsafe {\n        crate::field::bn254::decompose_hint(scalar)\n    };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n// docs:start:keccak256\npub fn keccak256<let N: u32>(input: [u8; N], message_size: u32) -> [u8; 32]\n// docs:end:keccak256\n{\n    crate::hash::keccak::keccak256(input, message_size)\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: StructDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(s, name, signature, for_each_field, quote {}, |fields| fields)\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H> where H: Hasher {\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default {\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default {\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H) where H: Hasher {}\n}\n\nimpl Hash for U128 {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        H::write(state, self.lo as Field);\n        H::write(state, self.hi as Field);\n    }\n}\n\nimpl<T, let N: u32> Hash for [T; N] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T] where T: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B) where A: Hash, B: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C) where A: Hash, B: Hash, C: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D) where A: Hash, B: Hash, C: Hash, D: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E) where A: Hash, B: Hash, C: Hash, D: Hash, E: Hash {\n    fn hash<H>(self, state: &mut H) where H: Hasher {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1), 0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1), EmbeddedCurvePoint {\n        x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n        y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n        is_infinite: false\n    }\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2), 0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2), EmbeddedCurvePoint {\n        x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n        y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3), 0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3), EmbeddedCurvePoint {\n        x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n        y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4), 0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4), EmbeddedCurvePoint {\n        x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n        y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5), 0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5), EmbeddedCurvePoint {\n        x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n        y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6), 0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6), EmbeddedCurvePoint {\n        x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n        y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7), 0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7), EmbeddedCurvePoint {\n        x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n        y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), 0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8), EmbeddedCurvePoint {\n        x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n        y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), 0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9), EmbeddedCurvePoint {\n        x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n        y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n        is_infinite: false\n    }\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), 0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10), EmbeddedCurvePoint {\n        x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n        y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n        is_infinite: false\n    }\n    );\n}\n","path":"std/hash/mod.nr"},"34":{"source":"use crate::hash::Hasher;\nuse crate::default::Default;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field;3],\n    state: [Field;4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        if message_size == N {\n            Poseidon2::hash_internal(input, N, false)\n        } else {\n            Poseidon2::hash_internal(input, message_size, true)\n        }\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result = Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::hash::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(input: [Field; N], in_len: u32, is_variable_length: bool) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv : Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher{\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv : Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"std/hash/poseidon2.nr"},"70":{"source":"use dep::protocol_types::{\n    header::{Header, HEADER_LENGTH}, address::{AztecAddress},\n    utils::{arr_copy_slice, field::{full_field_less_than, full_field_greater_than}},\n    merkle_tree::root::root_from_sibling_path,\n    constants::{GENERATOR_INDEX__NOTE_NULLIFIER, GENERATOR_INDEX__OUTER_NULLIFIER},\n    hash::poseidon2_hash_with_separator\n};\nuse dep::nft_contract::types::nft_note::NFTNote;\nuse aztec::{\n    note::{\n        utils::compute_note_hash_for_nullify,\n        note_header::NoteHeader,\n    },\n    // is it possible to connect to `sandbox` via `aztec-nargo`? #oracleresolve\n    oracle::{\n        // get_membership_witness::MembershipWitness,\n        get_nullifier_membership_witness::{\n            NullifierMembershipWitness,\n            NULLIFIER_MEMBERSHIP_WITNESS // 24\n        }\n    },\n};\nuse std::embedded_curve_ops::fixed_base_scalar_mul as derive_public_key;\nuse protocol_types::scalar::Scalar;\n\nfn main(\n    // TODO looks like it's possible to leave just the root from this #header_root\n    //      it's also #hidingprecise since at least global vars should be included as a `pub`\n    blockheader_serd: pub [Field; 24],\n    // TODO I guess it's possible to invent a context when sharing `nsk_m` is ok; though it will be narrow\n    nsk_m: [Field; 2],\n    // TODO should hash of the nullifier key be private? #hashednotehiding\n    //      seems it would be beneficial to deconstruct this with different hiding #hidingprecise\n    note_content: [Field; 3],\n    contract_address_as_field: pub Field,\n    nonce: Field,\n    // TODO is it possible to leverage this further?\n    storage_slot: Field,\n    // TODO check hiding #hidingprecise\n    //      #hashednotehiding\n    witness_membership_serd: [Field; 33],\n    // TODO check hiding #hidingprecise\n    //      my concern is that no problem for showing the root, but below that it starts leaking\n    low_nullifier_membership_witness_serd: [Field; NULLIFIER_MEMBERSHIP_WITNESS],\n    // debug_notehash: Field,\n    // debug_nsk_app: Field\n) {\n    let contract_address = AztecAddress::from_field(contract_address_as_field);\n\n    let mut note_the = NFTNote::deserialize_content(note_content);\n    note_the.set_header(NoteHeader::new(\n        contract_address,\n        nonce,\n        storage_slot\n    ));\n    let nsk_m = Scalar::new(nsk_m[0], nsk_m[1]);\n    assert_eq(\n        note_content[1], \n        derive_public_key(nsk_m).hash(),\n        \"wrong nullifier key\"\n    );\n    // #oracleresolve\n    // Header::deserialize(blockheader).prove_note_inclusion(note_the);\n    // let witness_membership = MembershipWitness { \n    //     index: witness_membership_serd[0], path: arr_copy_slice(\n    //         witness_membership_serd, [0; 32], 1\n    //     ) \n    // };\n\n    let blockheader = Header::deserialize(blockheader_serd);\n    let note_hashed_for_nullify = compute_note_hash_for_nullify(note_the);\n\n    // assert_eq(note_hashed_for_nullify, debug_notehash, \"wrong note-hashing\");\n    \n    assert_eq(\n        // TODO optimize by leaving only a root in the data exchange #header_root\n        blockheader.state.partial.note_hash_tree.root, \n        root_from_sibling_path(\n            note_hashed_for_nullify, \n            witness_membership_serd[0], \n            arr_copy_slice(\n                witness_membership_serd, [0; 32], 1\n            ) \n        ), \n        \"Proving note inclusion failed\"\n    );\n\n    // assert_eq(debug_nsk_app, poseidon2_hash_with_separator(\n    //     [nsk_m.hi, nsk_m.lo, contract_address_as_field],\n    //     48\n    // ), \"bad `nsk_app` algorithm\");\n\n    let nullifier = poseidon2_hash_with_separator([\n        contract_address_as_field,\n        poseidon2_hash_with_separator(\n            [\n                note_hashed_for_nullify,\n                poseidon2_hash_with_separator(\n                    [nsk_m.hi, nsk_m.lo, contract_address_as_field],\n                    48\n                )\n            ], \n            GENERATOR_INDEX__NOTE_NULLIFIER as Field\n        )\n    ], GENERATOR_INDEX__OUTER_NULLIFIER);\n    // pasta of `prove_nullifier_non_inclusion` from </home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/history/nullifier_non_inclusion.nr>\n    let witness = NullifierMembershipWitness::deserialize(low_nullifier_membership_witness_serd);\n    let low_nullifier_leaf = witness.leaf_preimage;\n    assert_eq(\n        blockheader.state.partial.nullifier_tree.root, // #header_root\n        root_from_sibling_path(\n            low_nullifier_leaf.hash(), \n            witness.index, witness.path\n        ), \n        \"Proving nullifier non-inclusion failed: Could not prove low nullifier inclusion\"\n    );\n    assert(\n        full_field_less_than(low_nullifier_leaf.nullifier, nullifier), \"Proving nullifier non-inclusion failed: low_nullifier.value < nullifier.value check failed\"\n    );\n    assert( \n        full_field_greater_than(low_nullifier_leaf.next_nullifier, nullifier)\n        | (low_nullifier_leaf.next_index == 0), \"Proving nullifier non-inclusion failed: low_nullifier.next_value > nullifier.value check failed\"\n    );\n}\n","path":"/home/serge/Desktop/note_historical_offline/circuit/src/main.nr"},"154":{"source":"use dep::protocol_types::{\n    abis::nullifier_leaf_preimage::{NullifierLeafPreimage, NULLIFIER_LEAF_PREIMAGE_LENGTH},\n    constants::NULLIFIER_TREE_HEIGHT, utils::arr_copy_slice\n};\n\n// INDEX_LENGTH + NULLIFIER_LEAF_PREIMAGE_LENGTH + NULLIFIER_TREE_HEIGHT\nglobal NULLIFIER_MEMBERSHIP_WITNESS: u32 = 24;\n\npub struct NullifierMembershipWitness {\n    index: Field,\n    leaf_preimage: NullifierLeafPreimage,\n    path: [Field; NULLIFIER_TREE_HEIGHT],\n}\n\nimpl NullifierMembershipWitness {\n    pub fn deserialize(fields: [Field; NULLIFIER_MEMBERSHIP_WITNESS]) -> Self {\n        let leaf_preimage_fields = arr_copy_slice(fields, [0; NULLIFIER_LEAF_PREIMAGE_LENGTH], 1);\n        Self {\n            index: fields[0],\n            leaf_preimage: NullifierLeafPreimage::deserialize(leaf_preimage_fields),\n            path: arr_copy_slice(\n                fields,\n                [0; NULLIFIER_TREE_HEIGHT],\n                1 + NULLIFIER_LEAF_PREIMAGE_LENGTH\n            )\n        }\n    }\n}\n\n#[oracle(getLowNullifierMembershipWitness)]\nunconstrained fn get_low_nullifier_membership_witness_oracle(\n    _block_number: u32,\n    _nullifier: Field\n) -> [Field; NULLIFIER_MEMBERSHIP_WITNESS] {}\n\n// Nullifier here refers to the nullifier we are looking to get non-inclusion proof for (by proving that a lower\n// nullifier's next_value is bigger than the nullifier)\nunconstrained pub fn get_low_nullifier_membership_witness(block_number: u32, nullifier: Field) -> NullifierMembershipWitness {\n    let fields = get_low_nullifier_membership_witness_oracle(block_number, nullifier);\n    NullifierMembershipWitness::deserialize(fields)\n}\n\n#[oracle(getNullifierMembershipWitness)]\nunconstrained fn get_nullifier_membership_witness_oracle(\n    _block_number: u32,\n    _nullifier: Field\n) -> [Field; NULLIFIER_MEMBERSHIP_WITNESS] {}\n\n// Nullifier here refers to the nullifier we are looking to get non-inclusion proof for (by proving that a lower\n// nullifier's next_value is bigger than the nullifier)\nunconstrained pub fn get_nullifier_membership_witness(block_number: u32, nullifier: Field) -> NullifierMembershipWitness {\n    let fields = get_nullifier_membership_witness_oracle(block_number, nullifier);\n    NullifierMembershipWitness::deserialize(fields)\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/oracle/get_nullifier_membership_witness.nr"},"165":{"source":"use crate::{\n    context::PrivateContext,\n    note::{note_header::NoteHeader, note_interface::{NullifiableNote, NoteInterface}}\n};\n\nuse dep::protocol_types::{\n    hash::{\n    compute_unique_note_hash, compute_siloed_note_hash as compute_siloed_note_hash,\n    compute_siloed_nullifier as compute_siloed_nullifier_from_preimage\n},\n    utils::arr_copy_slice\n};\n\npub fn compute_siloed_nullifier<Note, let N: u32>(\n    note_with_header: Note,\n    context: &mut PrivateContext\n) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let header = note_with_header.get_header();\n    let note_hash_for_nullify = compute_note_hash_for_nullify(note_with_header);\n    let inner_nullifier = note_with_header.compute_nullifier(context, note_hash_for_nullify);\n\n    compute_siloed_nullifier_from_preimage(header.contract_address, inner_nullifier)\n}\n\n// TODO(#7775): make this not impossible to understand\npub fn compute_note_hash_for_read_request<Note, let N: u32>(note: Note) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let note_hash = note.compute_note_hash();\n    let nonce = note.get_header().nonce;\n    let counter = note.get_header().note_hash_counter;\n\n    if counter != 0 {\n        note_hash\n    } else {\n        compute_unique_note_hash(nonce, note_hash)\n    }\n}\n\n// TODO(#7775): make this not impossible to understand\npub fn compute_note_hash_for_nullify_internal<Note, let N: u32>(\n    note: Note,\n    note_hash_for_read_request: Field\n) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let header = note.get_header();\n\n    if header.note_hash_counter != 0 {\n        if header.nonce == 0 {\n            // Case 1: Transient note\n            note_hash_for_read_request\n        } else {\n            // Case 2: Non-revertible note, nullified by a revertible nullifier\n            let unique_note_hash = compute_unique_note_hash(header.nonce, note_hash_for_read_request);\n            compute_siloed_note_hash(header.contract_address, unique_note_hash)\n        }\n    } else {\n        // Case 3: Note from a previous transaction\n        // note_hash_for_read_request is already the unique_note_hash in this case\n        compute_siloed_note_hash(header.contract_address, note_hash_for_read_request)\n    }\n}\n\n// TODO(#7775): nuke this commented out code - kept it around as it contains comments which might be helpful when tackling #7775\n// pub fn compute_note_hash_for_nullify<Note, let N: u32, let M: u32>(note: Note) -> Field where Note: NoteInterface<N> {\n//     let header = note.get_header();\n//     // There are 3 cases for reading a note intended for consumption:\n//     // 1. The note was inserted in this transaction, is revertible, or is not nullified by a revertible nullifier in\n//     //    the same transaction: (note_hash_counter != 0) & (nonce == 0)\n//     // 2. The note was inserted in this transaction, is non-revertible, and is nullified by a revertible nullifier in\n//     //    the same transaction: (note_hash_counter != 0) & (nonce != 0)\n//     // 3. The note was inserted in a previous transaction: (note_hash_counter == 0) & (nonce != 0)\n\n//     let note_hash = note.compute_note_hiding_point().x;\n\n//     if header.nonce == 0 {\n//         // Case 1.\n//         // If a note is transient, we just read the note_hash (kernel will hash it with nonce and silo by contract address).\n//         note_hash\n//     } else {\n//         // Case 2: If a note is non-revertible, and is nullified by a revertible nullifier, we cannot squash them in the\n//         // private reset circuit. Because if the tx reverts, we will have to keep the note hash and throw away the\n//         // nullifier.\n//         // And if the tx does not revert, both will be emitted. In which case, the nullifier must be created in the app\n//         // from the siloed note hash.\n//         // The kernel circuit will check that a nullifier with non-zero note_nonce is linked to a note hash, whose\n//         // siloed note hash matches the note hash specified in the nullifier.\n\n//         // Case 3: If a note is not from the current transaction, that means we are reading a settled note (from\n//         // tree) created in a previous TX. So we need the siloed_note_hash which has already been hashed with\n//         // nonce and then contract address. This hash will match the existing leaf in the note hash\n//         // tree, so the kernel can just perform a membership check directly on this hash/leaf.\n//         let unique_note_hash = compute_unique_note_hash(header.nonce, note_hash);\n//         compute_siloed_note_hash(header.contract_address, unique_note_hash)\n//         // IMPORTANT NOTE ON REDUNDANT SILOING BY CONTRACT ADDRESS: The note hash computed above is\n//         // \"siloed\" by contract address. When a note hash is computed solely for the purpose of\n//         // nullification, it is not strictly necessary to silo the note hash before computing\n//         // its nullifier. In other words, it is NOT NECESSARY for protocol security that a nullifier\n//         // be computed from a siloed note hash. After all, persistable note hashes and nullifiers are\n//         // siloed by the kernel circuit. That being said, the siloed note hash computed above CAN be\n//         // used for nullifier computation, and this achieves the (arguably unnecessary) property that\n//         // nullifiers are computed from a note hash's fully-computed note hash tree leaf.\n//     }\n// }\n\npub fn compute_note_hash_for_nullify<Note, let N: u32>(note: Note) -> Field where Note: NoteInterface<N> + NullifiableNote {\n    let note_hash_for_read_request = compute_note_hash_for_read_request(note);\n    compute_note_hash_for_nullify_internal(note, note_hash_for_read_request)\n}\n\nunconstrained pub fn compute_note_hash_and_optionally_a_nullifier<T, let N: u32, let S: u32>(\n    deserialize_content: fn([Field; N]) -> T,\n    note_header: NoteHeader,\n    compute_nullifier: bool,\n    serialized_note: [Field; S]\n) -> [Field; 4] where T: NoteInterface<N> + NullifiableNote {\n    let mut note = deserialize_content(arr_copy_slice(serialized_note, [0; N], 0));\n    note.set_header(note_header);\n\n    let note_hash = note.compute_note_hash();\n    let unique_note_hash = compute_unique_note_hash(note_header.nonce, note_hash);\n    let siloed_note_hash = compute_siloed_note_hash(note_header.contract_address, unique_note_hash);\n\n    let inner_nullifier = if compute_nullifier {\n        note.compute_nullifier_without_context()\n    } else {\n        0\n    };\n    // docs:start:compute_note_hash_and_optionally_a_nullifier_returns\n    [note_hash, unique_note_hash, siloed_note_hash, inner_nullifier]\n    // docs:end:compute_note_hash_and_optionally_a_nullifier_returns\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/aztec-nr/aztec/src/note/utils.nr"},"192":{"source":"use crate::{hash::merkle_hash, merkle_tree::merkle_tree::MerkleTree};\n\n// Calculate the Merkle tree root from the sibling path and leaf.\n//\n// The leaf is hashed with its sibling, and then the result is hashed\n// with the next sibling etc in the path. The last hash is the root.\n//\n// TODO(David/Someone): The cpp code is using a uint256, whereas its\n// TODO a bit simpler in Noir to just have a bit array.\n// TODO: I'd generally like to avoid u256 for algorithms like\n// this because it means we never even need to consider cases where\n// the index is greater than p.\npub fn root_from_sibling_path<let N: u32>(\n    leaf: Field,\n    leaf_index: Field,\n    sibling_path: [Field; N]\n) -> Field {\n    let mut node = leaf;\n    let indices: [u1; N] = leaf_index.to_le_bits();\n\n    for i in 0..N {\n        let (hash_left, hash_right) = if indices[i] == 1 {\n            (sibling_path[i], node)\n        } else {\n            (node, sibling_path[i])\n        };\n        node = merkle_hash(hash_left, hash_right);\n    }\n    node\n}\n\npub fn calculate_subtree_root<let N: u32>(leaves: [Field; N]) -> Field {\n    MerkleTree::new(leaves).get_root()\n}\n\n// These values are precomputed and we run tests to ensure that they\n// are correct. The values themselves were computed from the cpp code.\n//\n// Would be good if we could use width since the compute_subtree\n// algorithm uses depth.\npub fn calculate_empty_tree_root(depth: u32) -> Field {\n    if depth == 0 {\n        0\n    } else if depth == 1 {\n        0x0b63a53787021a4a962a452c2921b3663aff1ffd8d5510540f8e659e782956f1\n    } else if depth == 2 {\n        0x0e34ac2c09f45a503d2908bcb12f1cbae5fa4065759c88d501c097506a8b2290\n    } else if depth == 3 {\n        0x21f9172d72fdcdafc312eee05cf5092980dda821da5b760a9fb8dbdf607c8a20\n    } else if depth == 4 {\n        0x2373ea368857ec7af97e7b470d705848e2bf93ed7bef142a490f2119bcf82d8e\n    } else if depth == 5 {\n        0x120157cfaaa49ce3da30f8b47879114977c24b266d58b0ac18b325d878aafddf\n    } else if depth == 6 {\n        0x01c28fe1059ae0237b72334700697bdf465e03df03986fe05200cadeda66bd76\n    } else if depth == 7 {\n        0x2d78ed82f93b61ba718b17c2dfe5b52375b4d37cbbed6f1fc98b47614b0cf21b\n    } else if depth == 8 {\n        0x067243231eddf4222f3911defbba7705aff06ed45960b27f6f91319196ef97e1\n    } else if depth == 9 {\n        0x1849b85f3c693693e732dfc4577217acc18295193bede09ce8b97ad910310972\n    } else if depth == 10 {\n        0x2a775ea761d20435b31fa2c33ff07663e24542ffb9e7b293dfce3042eb104686\n    } else {\n        panic(f\"depth should be between 0 and 10\")\n    }\n}\n\n#[test]\nfn test_merkle_root_interop_test() {\n    // This is a test to ensure that we match the cpp implementation.\n    // You can grep for `TEST_F(root_rollup_tests, noir_interop_test)`\n    // to find the test that matches this.\n    let root = calculate_subtree_root([1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]);\n    assert(0x1a09d935ae110b4c861fcec8f9099ec30b4485022aeb3d3cf9d7168e38fdc231 == root);\n\n    let empty_root = calculate_subtree_root([0; 16]);\n    assert(0x2373ea368857ec7af97e7b470d705848e2bf93ed7bef142a490f2119bcf82d8e == empty_root);\n}\n\n#[test]\nfn test_empty_subroot() {\n    assert(calculate_empty_tree_root(0) == 0);\n\n    let expected_empty_root_2 = calculate_subtree_root([0; 2]);\n    assert(calculate_empty_tree_root(1) == expected_empty_root_2);\n\n    let expected_empty_root_4 = calculate_subtree_root([0; 4]);\n    assert(calculate_empty_tree_root(2) == expected_empty_root_4);\n\n    let expected_empty_root_8 = calculate_subtree_root([0; 8]);\n    assert(calculate_empty_tree_root(3) == expected_empty_root_8);\n\n    let expected_empty_root_16 = calculate_subtree_root([0; 16]);\n    assert(calculate_empty_tree_root(4) == expected_empty_root_16);\n\n    let expected_empty_root_32 = calculate_subtree_root([0; 32]);\n    assert(calculate_empty_tree_root(5) == expected_empty_root_32);\n\n    let expected_empty_root_64 = calculate_subtree_root([0; 64]);\n    assert(calculate_empty_tree_root(6) == expected_empty_root_64);\n\n    let expected_empty_root_128 = calculate_subtree_root([0; 128]);\n    assert(calculate_empty_tree_root(7) == expected_empty_root_128);\n\n    let expected_empty_root_256 = calculate_subtree_root([0; 256]);\n    assert(calculate_empty_tree_root(8) == expected_empty_root_256);\n\n    let expected_empty_root_512 = calculate_subtree_root([0; 512]);\n    assert(calculate_empty_tree_root(9) == expected_empty_root_512);\n\n    let expected_empty_root_1024 = calculate_subtree_root([0; 1024]);\n    assert(calculate_empty_tree_root(10) == expected_empty_root_1024);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/merkle_tree/root.nr"},"211":{"source":"use crate::{\n    abis::{\n    contract_class_function_leaf_preimage::ContractClassFunctionLeafPreimage,\n    function_selector::FunctionSelector, log_hash::{LogHash, ScopedLogHash, ScopedEncryptedLogHash},\n    note_hash::ScopedNoteHash, nullifier::ScopedNullifier\n},\n    address::{AztecAddress, EthAddress},\n    constants::{\n    FUNCTION_TREE_HEIGHT, GENERATOR_INDEX__SILOED_NOTE_HASH, GENERATOR_INDEX__OUTER_NULLIFIER,\n    GENERATOR_INDEX__VK, GENERATOR_INDEX__NOTE_HASH_NONCE, GENERATOR_INDEX__UNIQUE_NOTE_HASH,\n    MAX_ENCRYPTED_LOGS_PER_TX, MAX_NOTE_ENCRYPTED_LOGS_PER_TX\n},\n    merkle_tree::root::root_from_sibling_path,\n    messaging::l2_to_l1_message::{L2ToL1Message, ScopedL2ToL1Message},\n    recursion::verification_key::VerificationKey, traits::{is_empty, ToField},\n    utils::field::field_from_bytes_32_trunc\n};\nuse super::utils::field::field_from_bytes;\n\npub fn sha256_to_field<let N: u32>(bytes_to_hash: [u8; N]) -> Field {\n    let sha256_hashed = std::hash::sha256(bytes_to_hash);\n    let hash_in_a_field = field_from_bytes_32_trunc(sha256_hashed);\n\n    hash_in_a_field\n}\n\npub fn private_functions_root_from_siblings(\n    selector: FunctionSelector,\n    vk_hash: Field,\n    function_leaf_index: Field,\n    function_leaf_sibling_path: [Field; FUNCTION_TREE_HEIGHT]\n) -> Field {\n    let function_leaf_preimage = ContractClassFunctionLeafPreimage { selector, vk_hash };\n    let function_leaf = function_leaf_preimage.hash();\n    root_from_sibling_path(function_leaf, function_leaf_index, function_leaf_sibling_path)\n}\n\nfn compute_note_hash_nonce(tx_hash: Field, note_index_in_tx: u32) -> Field {\n    // Hashing tx hash with note index in tx is guaranteed to be unique\n    poseidon2_hash_with_separator(\n        [\n        tx_hash,\n        note_index_in_tx as Field\n    ],\n        GENERATOR_INDEX__NOTE_HASH_NONCE\n    )\n}\n\npub fn compute_unique_note_hash(nonce: Field, note_hash: Field) -> Field {\n    let inputs = [nonce, note_hash];\n    poseidon2_hash_with_separator(inputs, GENERATOR_INDEX__UNIQUE_NOTE_HASH)\n}\n\npub fn compute_siloed_note_hash(app: AztecAddress, unique_note_hash: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        unique_note_hash\n    ],\n        GENERATOR_INDEX__SILOED_NOTE_HASH\n    )\n}\n\n/// Siloing in the context of Aztec refers to the process of hashing a note hash with a contract address (this way\n/// the note hash is scoped to a specific contract). This is used to prevent intermingling of notes between contracts.\npub fn silo_note_hash(note_hash: ScopedNoteHash, tx_hash: Field, note_index_in_tx: u32) -> Field {\n    if note_hash.contract_address.is_zero() {\n        0\n    } else {\n        let nonce = compute_note_hash_nonce(tx_hash, note_index_in_tx);\n        let unique_note_hash = compute_unique_note_hash(nonce, note_hash.value());\n        compute_siloed_note_hash(note_hash.contract_address, unique_note_hash)\n    }\n}\n\npub fn compute_siloed_nullifier(app: AztecAddress, nullifier: Field) -> Field {\n    poseidon2_hash_with_separator(\n        [\n        app.to_field(),\n        nullifier\n    ],\n        GENERATOR_INDEX__OUTER_NULLIFIER\n    )\n}\n\npub fn silo_nullifier(nullifier: ScopedNullifier) -> Field {\n    if nullifier.contract_address.is_zero() {\n        nullifier.value() // Return value instead of 0 because the first nullifier's contract address is zero.\n    } else {\n        compute_siloed_nullifier(nullifier.contract_address, nullifier.value())\n    }\n}\n\npub fn silo_encrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    // We assume contract address has already been masked\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        accumulate_sha256([log_hash.contract_address.to_field(), log_hash.log_hash.value])\n    }\n}\n\npub fn mask_encrypted_log_hash(scoped_log: ScopedEncryptedLogHash) -> AztecAddress {\n    if scoped_log.contract_address.is_zero() {\n        AztecAddress::from_field(0)\n    } else if (scoped_log.log_hash.randomness == 0) {\n        scoped_log.contract_address\n    } else {\n        AztecAddress::from_field(\n            poseidon2_hash_with_separator(\n                [scoped_log.contract_address.to_field(), scoped_log.log_hash.randomness],\n                0\n            )\n        )\n    }\n}\n\nfn compute_siloed_unencrypted_log_hash(address: AztecAddress, log_hash: Field) -> Field {\n    accumulate_sha256([address.to_field(), log_hash])\n}\n\npub fn silo_unencrypted_log_hash(log_hash: ScopedLogHash) -> Field {\n    if log_hash.contract_address.is_zero() {\n        0\n    } else {\n        compute_siloed_unencrypted_log_hash(log_hash.contract_address, log_hash.value())\n    }\n}\n\npub fn merkle_hash(left: Field, right: Field) -> Field {\n    poseidon2_hash([left, right])\n}\n\npub fn stdlib_recursion_verification_key_compress_native_vk(_vk: VerificationKey) -> Field {\n    // Original cpp code\n    // stdlib::recursion::verification_key<CT::bn254>::compress_native(private_call.vk, GeneratorIndex::VK);\n    // The above cpp method is only ever called on verification key, so it has been special cased here\n    let _hash_index = GENERATOR_INDEX__VK;\n    0\n}\n\npub fn compute_l2_to_l1_hash(\n    contract_address: AztecAddress,\n    recipient: EthAddress,\n    content: Field,\n    rollup_version_id: Field,\n    chain_id: Field\n) -> Field {\n    let mut bytes: BoundedVec<u8, 160> = BoundedVec::new();\n\n    let inputs = [contract_address.to_field(), rollup_version_id, recipient.to_field(), chain_id, content];\n    for i in 0..inputs.len() {\n        // TODO are bytes be in fr.to_buffer() ?\n        let item_bytes: [u8; 32] = inputs[i].to_be_bytes();\n        for j in 0..32 {\n            bytes.push(item_bytes[j]);\n        }\n    }\n\n    sha256_to_field(bytes.storage)\n}\n\npub fn silo_l2_to_l1_message(msg: ScopedL2ToL1Message, rollup_version_id: Field, chain_id: Field) -> Field {\n    if msg.contract_address.is_zero() {\n        0\n    } else {\n        compute_l2_to_l1_hash(\n            msg.contract_address,\n            msg.message.recipient,\n            msg.message.content,\n            rollup_version_id,\n            chain_id\n        )\n    }\n}\n\n// Computes sha256 hash of 2 input hashes.\n//\n// NB: This method now takes in two 31 byte fields - it assumes that any input\n// is the result of a sha_to_field hash and => is truncated\n//\n// TODO(Jan and David): This is used for the encrypted_log hashes.\n// Can we check to see if we can just use hash_to_field or pedersen_compress here?\n//\npub fn accumulate_sha256(input: [Field; 2]) -> Field {\n    // This is a note about the cpp code, since it takes an array of Fields\n    // instead of a U128.\n    // 4 Field elements when converted to bytes will usually\n    // occupy 4 * 32 = 128 bytes.\n    // However, this function is making the assumption that each Field\n    // only occupies 128 bits.\n    //\n    // TODO(David): This does not seem to be getting guaranteed anywhere in the code?\n\n    // Concatentate two fields into 32x2 = 64 bytes\n    // accumulate_sha256 assumes that the inputs are pre-truncated 31 byte numbers\n    let mut hash_input_flattened = [0; 64];\n    for offset in 0..input.len() {\n        let input_as_bytes: [u8; 32] = input[offset].to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n\n    sha256_to_field(hash_input_flattened)\n}\n\n// Computes the final logs hash for a tx.\n// NB: this assumes MAX_ENCRYPTED_LOGS_PER_TX == MAX_UNENCRYPTED_LOGS_PER_TX\n// to avoid doubling code, since we can't define the byte len to be 32*N directly.\npub fn compute_tx_logs_hash(logs: [LogHash; MAX_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn compute_tx_note_logs_hash(logs: [LogHash; MAX_NOTE_ENCRYPTED_LOGS_PER_TX]) -> Field {\n    // Convert each field element into a byte array and append the bytes to `hash_input_flattened`\n    let mut hash_input_flattened = [0; MAX_NOTE_ENCRYPTED_LOGS_PER_TX * 32];\n    for offset in 0..MAX_NOTE_ENCRYPTED_LOGS_PER_TX {\n        let input_as_bytes: [u8; 32] = logs[offset].value.to_be_bytes();\n        for byte_index in 0..32 {\n            hash_input_flattened[offset * 32 + byte_index] = input_as_bytes[byte_index];\n        }\n    }\n    // Ideally we would push to a slice then hash, but there is no sha_slice\n    // Hardcode to 256 bytes for now\n    let mut hash = sha256_to_field(hash_input_flattened);\n    // Not having a 0 value hash for empty logs causes issues with empty txs\n    // used for padding. Returning early is currently unsupported.\n    // We always provide sorted logs here, so 0 being empty means all are empty.\n    if is_empty(logs[0]) {\n        hash = 0;\n    }\n    hash\n}\n\npub fn pedersen_hash<let N: u32>(inputs: [Field; N], hash_index: u32) -> Field {\n    std::hash::pedersen_hash_with_separator(inputs, hash_index)\n}\n\npub fn poseidon2_hash<let N: u32>(inputs: [Field; N]) -> Field {\n    std::hash::poseidon2::Poseidon2::hash(inputs, N)\n}\n\n#[no_predicates]\npub fn poseidon2_hash_with_separator<let N: u32, T>(\n    inputs: [Field; N],\n    separator: T\n) -> Field where T: ToField {\n    // We manually hash the inputs here, since we cannot express with the type system a constant size inputs array of N + 1\n    let in_len = N + 1;\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\npub fn poseidon2_hash_with_separator_slice<T>(inputs: [Field], separator: T) -> Field where T: ToField {\n    let in_len = inputs.len() + 1;\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n    sponge.absorb(separator.to_field());\n\n    for i in 0..inputs.len() {\n        sponge.absorb(inputs[i]);\n    }\n\n    sponge.squeeze()\n}\n\n#[no_predicates]\npub fn poseidon2_hash_bytes<let N: u32>(inputs: [u8; N]) -> Field {\n    // We manually hash the inputs here, since we cannot express with the type system a constant size inputs array of Math.ceil(N/31)\n    let mut in_len = N / 31;\n    let mut has_padding = false;\n    if N % 31 != 0 {\n        in_len += 1;\n        has_padding = true;\n    }\n\n    let two_pow_64 = 18446744073709551616;\n    let iv : Field = (in_len as Field) * two_pow_64;\n    let mut sponge = std::hash::poseidon2::Poseidon2::new(iv);\n\n    let mut current_field = [0; 31];\n    for i in 0..inputs.len() {\n        let index = i % 31;\n        current_field[index] = inputs[i];\n        if index == 30 {\n            sponge.absorb(field_from_bytes(current_field, false));\n            current_field = [0; 31];\n        }\n    }\n    if has_padding {\n        sponge.absorb(field_from_bytes(current_field, false));\n    }\n\n    sponge.squeeze()\n}\n\n#[test]\nfn smoke_sha256_to_field() {\n    let full_buffer = [\n        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n        20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n        40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n        80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,\n        100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119,\n        120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159\n    ];\n    let result = sha256_to_field(full_buffer);\n\n    assert(result == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184c7);\n\n    // to show correctness of the current ver (truncate one byte) vs old ver (mod full bytes):\n    let result_bytes = std::hash::sha256(full_buffer);\n    let truncated_field = crate::utils::field::field_from_bytes_32_trunc(result_bytes);\n    assert(truncated_field == result);\n    let mod_res = result + (result_bytes[31] as Field);\n    assert(mod_res == 0x448ebbc9e1a31220a2f3830c18eef61b9bd070e5084b7fa2a359fe729184e0);\n}\n\n#[test]\nfn compute_l2_l1_hash() {\n    // All zeroes\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(0), EthAddress::zero(), 0, 0, 0);\n    assert(hash_result == 0xb393978842a0fa3d3e1470196f098f473f9678e72463cb65ec4ab5581856c2);\n\n    // Non-zero case\n    let hash_result = compute_l2_to_l1_hash(AztecAddress::from_field(1), EthAddress::from_field(3), 5, 2, 4);\n    assert(hash_result == 0x3f88c1044a05e5340ed20466276500f6d45ca5603913b9091e957161734e16);\n}\n\n#[test]\nfn silo_l2_to_l1_message_matches_typescript() {\n    let version = 4;\n    let chainId = 5;\n\n    let hash = silo_l2_to_l1_message(\n        ScopedL2ToL1Message {\n        message: L2ToL1Message { recipient: EthAddress::from_field(1), content: 2, counter: 0 },\n        contract_address: AztecAddress::from_field(3)\n    },\n        version,\n        chainId\n    );\n\n    // The following value was generated by `l2_to_l1_message.test.ts`\n    let hash_from_typescript = 0x00c6155d69febb9d5039b374dd4f77bf57b7c881709aa524a18acaa0bd57476a;\n\n    assert_eq(hash, hash_from_typescript);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/hash.nr"},"212":{"source":"pub use dep::std::embedded_curve_ops::EmbeddedCurvePoint as Point;\nuse crate::{traits::{Deserialize, Empty, Hash, Serialize}, hash::poseidon2_hash};\n\nglobal POINT_LENGTH: u32 = 3;\n\nimpl Serialize<POINT_LENGTH> for Point {\n    fn serialize(self: Self) -> [Field; POINT_LENGTH] {\n        [self.x, self.y, self.is_infinite as Field]\n    }\n}\n\nimpl Hash for Point {\n    fn hash(self) -> Field {\n        poseidon2_hash(self.serialize())\n    }\n}\n\nimpl Empty for Point {\n    /// Note: Does not return a valid point on curve - instead represents an empty/\"unpopulated\" point struct (e.g.\n    /// empty/unpopulated value in an array of points).\n    fn empty() -> Self {\n        Point { x: 0, y: 0, is_infinite: false }\n    }\n}\n\nimpl Deserialize<POINT_LENGTH> for Point {\n    fn deserialize(serialized: [Field; POINT_LENGTH]) -> Point {\n        Point { x: serialized[0], y: serialized[1], is_infinite: serialized[2] as bool }\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/point.nr"},"239":{"source":"pub fn field_from_bytes<let N: u32>(bytes: [u8; N], big_endian: bool) -> Field {\n    assert(bytes.len() < 32, \"field_from_bytes: N must be less than 32\");\n    let mut as_field = 0;\n    let mut offset = 1;\n    for i in 0..N {\n        let mut index = i;\n        if big_endian {\n            index = N - i - 1;\n        }\n        as_field += (bytes[index] as Field) * offset;\n        offset *= 256;\n    }\n\n    as_field\n}\n\n// Convert a 32 byte array to a field element by truncating the final byte\npub fn field_from_bytes_32_trunc(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..15 {\n        // covers bytes 16..30 (31 is truncated and ignored)\n        low = low + (bytes32[15 + 15 - i] as Field) * v;\n        v = v * 256;\n        // covers bytes 0..14\n        high = high + (bytes32[14 - i] as Field) * v;\n    }\n    // covers byte 15\n    low = low + (bytes32[15] as Field) * v;\n\n    low + high * v\n}\n\n// TODO to radix returns u8, so we cannot use bigger radixes. It'd be ideal to use a radix of the maximum range-constrained integer noir supports\npub fn full_field_less_than(lhs: Field, rhs: Field) -> bool {\n    lhs.lt(rhs)\n}\n\npub fn full_field_greater_than(lhs: Field, rhs: Field) -> bool {\n    rhs.lt(lhs)\n}\n\n#[test]\nunconstrained fn bytes_field_test() {\n    // Tests correctness of field_from_bytes_32_trunc against existing methods\n    // Bytes representing 0x543e0a6642ffeb8039296861765a53407bba62bd1c97ca43374de950bbe0a7\n    let inputs = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28, 151, 202, 67, 55, 77, 233, 80, 187, 224, 167\n    ];\n    let field = field_from_bytes(inputs, true);\n    let return_bytes: [u8; 31] = field.to_be_bytes();\n    for i in 0..31 {\n        assert_eq(inputs[i], return_bytes[i]);\n    }\n    // 32 bytes - we remove the final byte, and check it matches the field\n    let inputs2 = [\n        84, 62, 10, 102, 66, 255, 235, 128, 57, 41, 104, 97, 118, 90, 83, 64, 123, 186, 98, 189, 28, 151, 202, 67, 55, 77, 233, 80, 187, 224, 167, 158\n    ];\n    let field2 = field_from_bytes_32_trunc(inputs2);\n    let return_bytes2: [u8; 31] = field.to_be_bytes();\n\n    for i in 0..31 {\n        assert_eq(return_bytes2[i], return_bytes[i]);\n    }\n    assert_eq(field2, field);\n}\n\n#[test]\nunconstrained fn max_field_test() {\n    // Tests the hardcoded value in constants.nr vs underlying modulus\n    // NB: We can't use 0-1 in constants.nr as it will be transpiled incorrectly to ts and sol constants files\n    let max_value = crate::constants::MAX_FIELD_VALUE;\n    assert_eq(max_value, 0 - 1);\n    // modulus == 0 is tested elsewhere, so below is more of a sanity check\n    let max_bytes: [u8; 32] = max_value.to_be_bytes();\n    let mod_bytes = std::field::modulus_be_bytes();\n    for i in 0..31 {\n        assert_eq(max_bytes[i], mod_bytes[i]);\n    }\n    assert_eq(max_bytes[31], mod_bytes[31] - 1);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/utils/field.nr"},"263":{"source":"global NULLIFIER_LEAF_PREIMAGE_LENGTH: u32 = 3;\n\nuse crate::{\n    abis::{read_request::ScopedReadRequest, side_effect::Readable}, hash::compute_siloed_nullifier,\n    merkle_tree::leaf_preimage::{LeafPreimage, IndexedTreeLeafPreimage}, traits::{Empty, Hash}\n};\n\npub struct NullifierLeafPreimage {\n    nullifier : Field,\n    next_nullifier :Field,\n    next_index : u32,\n}\n\nimpl Empty for NullifierLeafPreimage {\n    fn empty() -> Self {\n        Self { nullifier: 0, next_nullifier: 0, next_index: 0 }\n    }\n}\n\nimpl Hash for NullifierLeafPreimage {\n    fn hash(self) -> Field {\n        if self.is_empty() {\n            0\n        } else {\n            crate::hash::poseidon2_hash(self.serialize())\n        }\n    }\n}\n\nimpl LeafPreimage for NullifierLeafPreimage {\n    fn get_key(self) -> Field {\n        self.nullifier\n    }\n\n    fn as_leaf(self) -> Field {\n        self.hash()\n    }\n}\n\nimpl IndexedTreeLeafPreimage for NullifierLeafPreimage {\n    fn get_key(self) -> Field {\n        self.nullifier\n    }\n\n    fn get_next_key(self) -> Field {\n        self.next_nullifier\n    }\n\n    fn as_leaf(self) -> Field {\n        self.hash()\n    }\n}\n\nimpl Readable<ScopedReadRequest> for NullifierLeafPreimage {\n    fn assert_match_read_request(self, read_request: ScopedReadRequest) {\n        let siloed_value = compute_siloed_nullifier(read_request.contract_address, read_request.value());\n        assert_eq(self.nullifier, siloed_value, \"Value of the nullifier leaf does not match read request\");\n    }\n}\n\nimpl NullifierLeafPreimage {\n    pub fn is_empty(self) -> bool {\n        (self.nullifier == 0) & (self.next_nullifier == 0) & (self.next_index == 0)\n    }\n\n    pub fn serialize(self) -> [Field; NULLIFIER_LEAF_PREIMAGE_LENGTH] {\n        [self.nullifier, self.next_nullifier, self.next_index as Field]\n    }\n\n    pub fn deserialize(fields: [Field; NULLIFIER_LEAF_PREIMAGE_LENGTH]) -> Self {\n        Self { nullifier: fields[0], next_nullifier: fields[1], next_index: fields[2] as u32 }\n    }\n}\n\nimpl Eq for NullifierLeafPreimage {\n    fn eq(self, other: Self) -> bool {\n        (self.nullifier == other.nullifier)\n            & (self.next_nullifier == other.next_nullifier)\n            & (self.next_index == other.next_index)\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let item = NullifierLeafPreimage::empty();\n    let serialized = item.serialize();\n    let deserialized = NullifierLeafPreimage::deserialize(serialized);\n    assert(item.eq(deserialized));\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/abis/nullifier_leaf_preimage.nr"},"302":{"source":"use crate::{\n    address::{AztecAddress, EthAddress}, abis::gas_fees::GasFees, constants::GLOBAL_VARIABLES_LENGTH,\n    traits::{Deserialize, Empty, Serialize}, utils::reader::Reader\n};\n\n// docs:start:global-variables\npub struct GlobalVariables {\n    chain_id : Field,\n    version : Field,\n    block_number : Field,\n    slot_number : Field,\n    timestamp : u64,\n    coinbase : EthAddress,\n    fee_recipient : AztecAddress,\n    gas_fees : GasFees\n}\n// docs:end:global-variables\n\nimpl GlobalVariables {\n    fn is_empty(self) -> bool {\n        (self.chain_id == 0)\n            & (self.version == 0)\n            & (self.block_number == 0)\n            & (self.slot_number == 0)\n            & (self.timestamp == 0)\n            & (self.coinbase.is_zero())\n            & (self.fee_recipient.is_zero())\n            & (self.gas_fees.is_empty())\n    }\n}\n\nimpl Serialize<GLOBAL_VARIABLES_LENGTH> for GlobalVariables {\n    fn serialize(self) -> [Field; GLOBAL_VARIABLES_LENGTH] {\n        let mut serialized: BoundedVec<Field, GLOBAL_VARIABLES_LENGTH> = BoundedVec::new();\n\n        serialized.push(self.chain_id);\n        serialized.push(self.version);\n        serialized.push(self.block_number);\n        serialized.push(self.slot_number);\n        serialized.push(self.timestamp as Field);\n        serialized.push(self.coinbase.to_field());\n        serialized.push(self.fee_recipient.to_field());\n        serialized.extend_from_array(self.gas_fees.serialize());\n\n        serialized.storage\n    }\n}\n\nimpl Deserialize<GLOBAL_VARIABLES_LENGTH> for GlobalVariables {\n    fn deserialize(serialized: [Field; GLOBAL_VARIABLES_LENGTH]) -> GlobalVariables {\n        let mut reader = Reader::new(serialized);\n        GlobalVariables {\n            chain_id: reader.read(),\n            version: reader.read(),\n            block_number: reader.read(),\n            slot_number: reader.read(),\n            timestamp: reader.read() as u64,\n            coinbase: EthAddress::from_field(reader.read()),\n            fee_recipient: AztecAddress::from_field(reader.read()),\n            gas_fees: reader.read_struct(GasFees::deserialize)\n        }\n    }\n}\n\nimpl Eq for GlobalVariables {\n    fn eq(self, other: GlobalVariables) -> bool {\n        (self.chain_id == other.chain_id)\n            & (self.version == other.version)\n            & (self.block_number == other.block_number)\n            & (self.slot_number == other.slot_number)\n            & (self.timestamp == other.timestamp)\n            & (self.coinbase == other.coinbase)\n            & (self.fee_recipient == other.fee_recipient)\n            & (self.gas_fees == other.gas_fees)\n    }\n}\n\nimpl Empty for GlobalVariables {\n    fn empty() -> Self {\n        Self {\n            chain_id: 0,\n            version: 0,\n            block_number: 0,\n            slot_number: 0,\n            timestamp: 0,\n            coinbase: EthAddress::empty(),\n            fee_recipient: AztecAddress::empty(),\n            gas_fees: GasFees::empty()\n        }\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let vars = GlobalVariables::empty();\n    let _serialized = vars.serialize();\n    let _deserialized = GlobalVariables::deserialize(_serialized);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/abis/global_variables.nr"},"316":{"source":"use crate::{\n    abis::{\n    append_only_tree_snapshot::{AppendOnlyTreeSnapshot, APPEND_ONLY_TREE_SNAPSHOT_LENGTH},\n    global_variables::GlobalVariables\n},\n    constants::{\n    GENERATOR_INDEX__BLOCK_HASH, GLOBAL_VARIABLES_LENGTH, HEADER_LENGTH, STATE_REFERENCE_LENGTH,\n    CONTENT_COMMITMENT_LENGTH\n},\n    hash::poseidon2_hash_with_separator, state_reference::StateReference,\n    traits::{Deserialize, Empty, Hash, Serialize}, utils::arr_copy_slice,\n    content_commitment::ContentCommitment\n};\n\n// docs:start:header\npub struct Header {\n    last_archive: AppendOnlyTreeSnapshot,\n    content_commitment: ContentCommitment,\n    state: StateReference,\n    global_variables: GlobalVariables,\n    total_fees: Field\n}\n// docs:end:header\n\nimpl Eq for Header {\n    fn eq(self, other: Self) -> bool {\n        self.last_archive.eq(other.last_archive)\n            & self.content_commitment.eq(other.content_commitment)\n            & self.state.eq(other.state)\n            & self.global_variables.eq(other.global_variables)\n            & self.total_fees.eq(other.total_fees)\n    }\n}\n\nimpl Serialize<HEADER_LENGTH> for Header {\n    fn serialize(self) -> [Field; HEADER_LENGTH] {\n        let mut fields: BoundedVec<Field, HEADER_LENGTH> = BoundedVec::new();\n\n        fields.extend_from_array(self.last_archive.serialize());\n        fields.extend_from_array(self.content_commitment.serialize());\n        fields.extend_from_array(self.state.serialize());\n        fields.extend_from_array(self.global_variables.serialize());\n        fields.push(self.total_fees);\n\n        fields.storage\n    }\n}\n\nimpl Deserialize<HEADER_LENGTH> for Header {\n    fn deserialize(serialized: [Field; HEADER_LENGTH]) -> Self {\n        let mut offset = 0;\n\n        let last_archive_fields = arr_copy_slice(serialized, [0; APPEND_ONLY_TREE_SNAPSHOT_LENGTH], offset);\n        offset = offset + APPEND_ONLY_TREE_SNAPSHOT_LENGTH;\n\n        let content_commitment_fields = arr_copy_slice(serialized, [0; CONTENT_COMMITMENT_LENGTH], offset);\n        offset = offset + CONTENT_COMMITMENT_LENGTH;\n\n        let state_fields = arr_copy_slice(serialized, [0; STATE_REFERENCE_LENGTH], offset);\n        offset = offset + STATE_REFERENCE_LENGTH;\n\n        let global_variables_fields = arr_copy_slice(serialized, [0; GLOBAL_VARIABLES_LENGTH], offset);\n        offset = offset + GLOBAL_VARIABLES_LENGTH;\n\n        let total_fees = serialized[offset];\n\n        Header {\n            last_archive: AppendOnlyTreeSnapshot::deserialize(last_archive_fields),\n            content_commitment: ContentCommitment::deserialize(content_commitment_fields),\n            state: StateReference::deserialize(state_fields),\n            global_variables: GlobalVariables::deserialize(global_variables_fields),\n            total_fees\n        }\n    }\n}\n\nimpl Empty for Header {\n    fn empty() -> Self {\n        Self {\n            last_archive: AppendOnlyTreeSnapshot::zero(),\n            content_commitment: ContentCommitment::empty(),\n            state: StateReference::empty(),\n            global_variables: GlobalVariables::empty(),\n            total_fees: 0\n        }\n    }\n}\n\nimpl Hash for Header {\n    fn hash(self) -> Field {\n        poseidon2_hash_with_separator(self.serialize(), GENERATOR_INDEX__BLOCK_HASH)\n    }\n}\n\n#[test]\nfn serialization_of_empty() {\n    let header = Header::empty();\n    let serialized = header.serialize();\n    let deserialized = Header::deserialize(serialized);\n    assert(header.eq(deserialized));\n}\n\n#[test]\nfn hash_smoke() {\n    let header = Header::empty();\n    let _hashed = header.hash();\n}\n\n#[test]\nfn empty_hash_is_zero() {\n    let header = Header::empty();\n    let hash = header.hash();\n\n    // Value from new_contract_data.test.ts \"computes empty hash\" test\n    let test_data_empty_hash = 0x1c97ed6fbc35f8b400d31bd38ce5cc938921e0cf2e20159d316f8c7011f9f42c;\n    assert_eq(hash, test_data_empty_hash);\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/header.nr"},"321":{"source":"use crate::{constants::ETH_ADDRESS_LENGTH, traits::{Empty, ToField, Serialize, Deserialize}, utils};\n\npub struct EthAddress{\n    inner : Field\n}\n\nimpl Eq for EthAddress {\n    fn eq(self, other: Self) -> bool {\n        self.to_field() == other.to_field()\n    }\n}\n\nimpl Empty for EthAddress {\n    fn empty() -> Self {\n        Self { inner: 0 }\n    }\n}\n\nimpl ToField for EthAddress {\n    fn to_field(self) -> Field {\n        self.inner\n    }\n}\n\nimpl Serialize<ETH_ADDRESS_LENGTH> for EthAddress {\n    fn serialize(self: Self) -> [Field; ETH_ADDRESS_LENGTH] {\n        [self.inner]\n    }\n}\n\nimpl Deserialize<ETH_ADDRESS_LENGTH> for EthAddress {\n    fn deserialize(fields: [Field; ETH_ADDRESS_LENGTH]) -> Self {\n        EthAddress::from_field(fields[0])\n    }\n}\n\nimpl EthAddress {\n    pub fn zero() -> Self {\n        Self { inner: 0 }\n    }\n\n    pub fn from_field(field: Field) -> Self {\n        field.assert_max_bit_size(160);\n        Self { inner: field }\n    }\n\n    pub fn is_zero(self) -> bool {\n        self.inner == 0\n    }\n\n    pub fn assert_is_zero(self) {\n        assert(self.to_field() == 0);\n    }\n\n    pub fn conditional_assign(predicate: bool, lhs: Self, rhs: Self) -> Self {\n        let result = utils::conditional_assign(predicate, rhs.to_field(), lhs.to_field());\n        Self { inner: result }\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-protocol-circuits/crates/types/src/address/eth_address.nr"},"335":{"source":"use dep::aztec::{\n    note::utils::compute_note_hash_for_nullify, keys::getters::get_nsk_app, oracle::random::random,\n    prelude::{NullifiableNote, NoteHeader, PrivateContext},\n    protocol_types::{constants::GENERATOR_INDEX__NOTE_NULLIFIER, hash::poseidon2_hash_with_separator, traits::{Empty, Eq}},\n    macros::notes::partial_note\n};\n\n#[partial_note(quote { token_id})]\npub struct NFTNote {\n    // ID of the token\n    token_id: Field,\n    // The nullifying public key hash is used with the nsk_app to ensure that the note can be privately spent.\n    npk_m_hash: Field,\n    // Randomness of the note to hide its contents\n    randomness: Field,\n}\n\nimpl NullifiableNote for NFTNote {\n    fn compute_nullifier(self, context: &mut PrivateContext, note_hash_for_nullify: Field) -> Field {\n        let secret = context.request_nsk_app(self.npk_m_hash);\n        poseidon2_hash_with_separator(\n            [\n            note_hash_for_nullify,\n            secret\n        ],\n            GENERATOR_INDEX__NOTE_NULLIFIER as Field\n        )\n    }\n\n    unconstrained fn compute_nullifier_without_context(self) -> Field {\n        let note_hash_for_nullify = compute_note_hash_for_nullify(self);\n        let secret = get_nsk_app(self.npk_m_hash);\n        poseidon2_hash_with_separator(\n            [\n            note_hash_for_nullify,\n            secret\n        ],\n            GENERATOR_INDEX__NOTE_NULLIFIER as Field\n        )\n    }\n}\n\nimpl NFTNote {\n    pub fn new(token_id: Field, npk_m_hash: Field) -> Self {\n        // We use the randomness to preserve the privacy of the note recipient by preventing brute-forcing, so a\n        // malicious sender could use non-random values to make the note less private. But they already know the full\n        // note pre-image anyway, and so the recipient already trusts them to not disclose this information. We can\n        // therefore assume that the sender will cooperate in the random value generation.\n        let randomness = unsafe {\n            random()\n        };\n        NFTNote { token_id, npk_m_hash, randomness, header: NoteHeader::empty() }\n    }\n}\n\nimpl Eq for NFTNote {\n    fn eq(self, other: Self) -> bool {\n        (self.token_id == other.token_id)\n            & (self.npk_m_hash == other.npk_m_hash)\n            & (self.randomness == other.randomness)\n    }\n}\n","path":"/home/serge/nargo/github.com/AztecProtocol/aztec-packages/aztec-packages-v0.57.0/noir-projects/noir-contracts/contracts/nft_contract/src/types/nft_note.nr"}},"names":["main"],"brillig_names":["decompose_hint","lt_32_hint","lte_16_hint","directive_integer_quotient","directive_invert"]}